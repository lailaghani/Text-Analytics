{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "418a6d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tabulate import tabulate\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d32ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample dataset\n",
    "dataset = [\"I love playing football on the weekends\",\n",
    "           \"I enjoy hiking and camping in the mountains\",\n",
    "           \"I like to read books and watch movies\",\n",
    "           \"I prefer playing video games over sports\",\n",
    "           \"I love listening to music and going to concerts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7453b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\laila\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\laila\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Preprocessing\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess(text):\n",
    "    # Remove non-alphabetic characters and lowercase\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text.lower())\n",
    "    # Tokenize\n",
    "    tokens = text.split()\n",
    "    # Remove stopwords and lemmatize\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
    "    # Join tokens back into a string\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "preprocessed_dataset = [preprocess(doc) for doc in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0840af28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['love playing football weekend',\n",
       " 'enjoy hiking camping mountain',\n",
       " 'like read book watch movie',\n",
       " 'prefer playing video game sport',\n",
       " 'love listening music going concert']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "393740a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the dataset\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(preprocessed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "80eb4d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of clusters\n",
    "k = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "09ae9eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=2)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a k-means model and fit it to the data\n",
    "km = KMeans(n_clusters=k)\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "131e2bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the clusters for each document\n",
    "y_pred = km.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d46a0153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document                                           Predicted Cluster\n",
      "-----------------------------------------------  -------------------\n",
      "I love playing football on the weekends                            0\n",
      "I enjoy hiking and camping in the mountains                        0\n",
      "I like to read books and watch movies                              1\n",
      "I prefer playing video games over sports                           0\n",
      "I love listening to music and going to concerts                    0\n"
     ]
    }
   ],
   "source": [
    "# Display the document and its predicted cluster in a table\n",
    "table_data = [[\"Document\", \"Predicted Cluster\"]]\n",
    "table_data.extend([[doc, cluster] for doc, cluster in zip(dataset, y_pred)])\n",
    "print(tabulate(table_data, headers=\"firstrow\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2883b82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top terms per cluster:\n",
      "Cluster 0:\n",
      " love\n",
      " playing\n",
      " football\n",
      " weekend\n",
      " enjoy\n",
      " camping\n",
      " mountain\n",
      " hiking\n",
      " sport\n",
      " music\n",
      "\n",
      "Cluster 1:\n",
      " book\n",
      " like\n",
      " read\n",
      " movie\n",
      " watch\n",
      " camping\n",
      " concert\n",
      " enjoy\n",
      " football\n",
      " game\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print top terms per cluster\n",
    "print(\"\\nTop terms per cluster:\")\n",
    "order_centroids = km.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "for i in range(k):\n",
    "    print(\"Cluster %d:\" % i)\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "49ba23bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Purity: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Calculate purity\n",
    "total_samples = len(y_pred)\n",
    "cluster_label_counts = [Counter(y_pred)]\n",
    "purity = sum(max(cluster.values()) for cluster in cluster_label_counts) / total_samples\n",
    "\n",
    "print(\"Purity:\", purity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba535cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
